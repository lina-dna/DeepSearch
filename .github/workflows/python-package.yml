# This workflow will install Python dependencies, run tests and lint with a single version of Python
# For more information see: https://help.github.com/actions/language-and-framework-guides/using-python-with-github-actions

name: News Crawler

on:
  push:
    branches:
      - secret_test

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - name: env
      env:
        ES_HOSTS: '${{ secrets.ES_HOSTS }}'
        ES_ID: '${{ secrets.ES_ID }}'
        ES_PASSWD: '${{ secrets.ES_PASSWD }}'
        STRAPI_HOSTS: '${{ secrets.STRAPI_HOSTS }}'
      run: |
        echo ${{secrets.ES_HOSTS}} | sed 's/./& /g' 
        python -c 'import os; print(os.getenv("ES_HOSTS"))'
        python -c 'import os; print(os.getenv("ES_ID"))'
        python -c 'import os; print(os.getenv("STRAPI_HOSTS"))'
        python -c 'import os; print(os.environ.get("STRAPI_HOSTS"))'
        
      
    - uses: actions/checkout@v2
    - name: Set up Python 3.7
      uses: actions/setup-python@v2
#       env:
#         ES_HOSTS: '${{ secrets.ES_HOSTS }}'
#         ES_ID: '${{ secrets.ES_ID }}'
#         ES_PASSWD: '${{ secrets.ES_PASSWD }}'
#         STRAPI_HOSTS: '${{ secrets.STRAPI_HOSTS }}'
      with:
        python-version: 3.7
    - name: Install chrome
      run: |
        sudo apt-get install unzip chromium-browser
        sudo wget https://chromedriver.storage.googleapis.com/91.0.4472.101/chromedriver_linux64.zip
        sudo unzip chromedriver_linux64.zip
        sudo chmod +x chromedriver
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    - name: Run Crawler
      run: python crawler.py
      working-directory: ./crawler
